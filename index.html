<meta name="description" content="Muzhi Zhu&#39;s home page">
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<link rel="shortcut icon" href="img/zju.png">
<title>Muzhi Zhu's Homepage @ Zhejiang University</title>

<body>
<div id="layout-content" style="margin-top:25px">

<table>
    <tbody>
        <tr>
            <td width="670">
                <div id="toptitle">
                    <h1>Muzhi Zhu &nbsp; 朱慕之<!--<img src="lk_chinesename.PNG" height="32px" style="margin-bottom:-5px" alt=''>--></h1>
                </div>
                <!-- <h3>Graduate Student</h3> -->
                <p>
                    <FONT size=3 face="Times New Roman">Ph.D. Candidate</FONT><br>
                    <br>
                    State Key Lab of CAD & CG<br>
                    College of Computer Science and Technology<br>
                    Zhejiang University <br>
                    Zhejiang, China. 310058.<br>
                    <br>
                    <!--Office: Room 108, Zetong Building, Yuquan Campus-->
                    
                    Github: <a href="https://github.com/Z-MU-Z">Z-MU-Z</a>
                    <br>
                    Scholar: <a href="https://scholar.google.com/citations?user=064gBH4AAAAJ&hl=en"> Google scholar</a>
                    <br>
                    Email: zhumuzhi &alpha;t zju d&omicron;t edu d&omicron;t cn
                </p>
            </td>
            <td>
                <img src="./img/2024.jpeg" border="0" width="300">
            </td>

        </tr>
    </tbody>
</table>

<h2>Biography</h2>
<p>
    I'm currently a first-year Ph.D student of the <a href="http://www.cs.zju.edu.cn/">College of Computer Science and Technology</a> at <a href="https://www.zju.edu.cn/">Zhejiang University</a>, fortunately advised by <a href="https://cshen.github.io">Prof. Chunhua Shen</a> and <a href="https://stan-haochen.github.io/">Prof. Hao Chen</a> .  Before that I got my bachelor's degree in Artificial Intelligence Honor Class at Shanghai Jiao Tong University. Before I got to Shanghai Jiao Tong University, all my life was spent in my hometown, Hangzhou, Zhejiang province.
</p>

<p>
    In my daily life, I have a strong interest in painting, architecture, music, classical Chinese literature and <a href="https://blush-sweatpants-711.notion.site/a00ed762e0db452d8abb26366c458911?pvs=4"> poetry </a>.
</p>
  
<h2>Research Interests</h2>
<p>
    <!--My research interests include AI & Science, Graph Neural Network. In particular, I am interested in promoting the development of science especially physical science with artificial intelligence, including discovering the conservation law, the new material. Also I work on improving the AI with physical science.-->
    MLLMs, Computer Vision, AI for science
    
    <!-- <p align="justify"><span style="color:#ff0000"><b>I am looking forward to a visiting student position recently! Feel free to drop me an e-mail. </b></span></p> -->
</p>

<h2>News<small></small></h2>
<ul>
    <li>
        [2025.3] One paper was accepted by CVPR.
    </li>
    <li>
        [2024.10] Two papers were accepted by NeurIPS.
    </li>
    <li>
        [2024.05] One paper was accepted by ICML.
    </li>
    <li>
        [2024.03] One paper was accepted by CVPR.
    </li>
    <li>
        [2024.01] Two paper were accepted by ICLR (One Spotlight).
    </li>
    <li>
        [2023.07] One paper was accepted by ICCV.
    </li>
</ul>

<!--<p align="justify"><span style="color:#ff0000"><b>I am looking forward to working with researchers in the field of AI & Science (also a Ph.D. position)! Feel free to drop me an <a href="mailto:lk2017@zju.edu.cn">e-mail</a>. </b></span></p>
-->
<h2>Selected Publications<small></small></h2>
<head>
    <style>
        .container {
            display: flex;
            justify-content: space-between;
        }
        .image-side {
            flex-basis: 20%;
            position: relative;
            box-shadow: 10px 10px 5px grey;
        }
        .label {
            position: absolute; 
            right: 0; 
            bottom: 3;
            padding: 3px;
            font-size: 12px;
            background-color: skyblue; 
        }
        .text-side {
            flex-basis: 80%;
        }
    </style>
</head>

<p>
    
    <div class="container">
        <div class="image-side">
            <img src="./paper_img/SegAgent.png" border="0" width="240">
            <div class="label">CVPR'25</div>
        </div>
        <div class="text-side">
            <ul>
                <strong> SegAgent: Exploring Pixel Understanding Capabilities in MLLMs by Imitating Human Annotator Trajectories </strong> <br>
                <strong>Muzhi Zhu</strong>, Yuzhuo Tian, Hao Chen, Chunluan Zhou, Qingpei Guo, Yang Liu, Ming Yang, Chunhua Shen <br>
                Conference on Computer Vision and Pattern Recognition (CVPR'25), 2025. <br>
                 <a href="https://github.com/aim-uofa/SegAgent">[code]</a> <a href="https://arxiv.org/abs/2503.08625">[paper]</a> <a href="https://aim-uofa.github.io/SegAgent/">[page]</a>
            </ul>
        </div>
    </div>
</p>
    <div class="container">
        <div class="image-side">
            <img src="./paper_img/GAL.jpeg" border="0" width="240">
            <div class="label">ICML'24</div>
        </div>
        <div class="text-side">
            <ul>
                <strong> Generative Active Learning for Long-tailed Instance Segmentation </strong><br>
                <strong>Muzhi Zhu*</strong>, Chengxiang Fan*, Hao Chen, Yang Liu, Weian Mao, Xiaogang Xu, Chunhua Shen . <br>
                Forty-first International Conference on Machine Learning (ICML'24), 2024. <br>
                <a href="https://github.com/aim-uofa/DiverGen">[code]</a> <a href="https://openreview.net/forum?id=ofXRBPtol3">[paper]</a> 
            </ul>
        </div>
    </div>
</p>
<p>
    <!-- <h1>Unleashing the Potential of the Diffusion Model in Few-shot Semantic Segmentation</h1>

[Muzhi Zhu](https://scholar.google.com/citations?user=064gBH4AAAAJ&hl=en)<sup>1*</sup>, &nbsp;
[Yang Liu](https://scholar.google.com/citations?user=9JcQ2hwAAAAJ&hl=en)<sup>1*</sup>, &nbsp;
Zekai Luo<sup>1*</sup>, &nbsp; 
[Chenchen Jing](https://jingchenchen.github.io/)<sup>1</sup>, &nbsp;
[Hao Chen](https://stan-haochen.github.io/)<sup>1</sup>, &nbsp;
[Guangkai Xu](https://scholar.google.com.hk/citations?user=v35sbGEAAAAJ&hl=en)<sup>1</sup>, &nbsp;
[Xinlong Wang](https://www.xloong.wang/)<sup>2</sup>, &nbsp;
[Chunhua Shen](https://cshen.github.io/)<sup>1</sup> --> 
<!-- https://openreview.net/forum?id=3ACXaFxjTy --> 
<!-- https://github.com/aim-uofa/DiffewS -->
    <div class="container">
    <div class="image-side">
        <img src="./paper_img/diffews.png" border="0" width="240">
        <div class="label">NeurIPS'24</div>
    </div>
    <div class="text-side">
        <ul>
            <strong> Unleashing the Potential of the Diffusion Model in Few-shot Semantic Segmentation </strong><br>
            <strong>Muzhi Zhu*</strong>, Yang Liu*, Zekai Luo*, Chenchen Jing, Hao Chen, Guangkai Xu, Xinlong Wang, Chunhua Shen . <br>
            Advances in Neural Information Processing Systems (NeurIPS'24), 2024. <br>
            <a href="https://github.com/aim-uofa/DiffewS">[code]</a> <a href="https://openreview.net/forum?id=3ACXaFxjTy">[paper]</a>
        </ul>
    </div>
</div>
</p>
<p>
    <div class="container">
        <div class="image-side">
           <img src="./paper_img/Segprompt.png" border="0" width="240">
           <div class="label">ICCV'23</div>
        </div>
        <div class="text-side">
            <ul>
                <strong>Segprompt: Boosting open-world segmentation via category-level prompt learning</strong> <br>
                <strong>Muzhi Zhu</strong>, Hengtao Li, Hao Chen, Chengxiang Fan, Weian Mao, Chenchen Jing, Yifan Liu, Chunhua Shen. <br>
                Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV'23), 2023. <br>
                <a href="https://github.com/aim-uofa/SegPrompt">[code]</a> <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_SegPrompt_Boosting_Open-World_Segmentation_via_Category-Level_Prompt_Learning_ICCV_2023_paper.pdf">[paper]</a>
            </ul>
        </div>
    </div>
</p>
<p>
    
    <div class="container">
        <div class="image-side">
            <img src="./paper_img/DiverGen.png" border="0" width="240">
            <div class="label">CVPR'24</div>
        </div>
        <div class="text-side">
            <ul>
                <strong> DiverGen: Improving Instance Segmentation by Learning Wider Data Distribution with More Diverse Generative Data</strong> <br>
                Chengxiang Fan*, <strong>Muzhi Zhu*</strong>, Hao Chen, Yang Liu, Weijia Wu, Huaqi Zhang, Chunhua Shen . <br>
                Conference on Computer Vision and Pattern Recognition (CVPR'24), 2024. <br>
                 <a href="https://github.com/aim-uofa/DiverGen">[code]</a> <a href="https://openreview.net/forum?id=VLjVKiuodA">[paper]</a> 
            </ul>
        </div>
    </div>
</p>

<!-- @inproceedings{
    mao2024de,
    title={De novo Protein Design Using Geometric Vector Field Networks},
    author={Weian Mao and Muzhi Zhu and Zheng Sun and Shuaike Shen and Lin Yuanbo Wu and Hao Chen and Chunhua Shen},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=9UIGyJJpay}
    } -->
<p>
    <div class="container">
        <div class="image-side">
            <img src="./paper_img/VFN.png" border="0" width="240">
            <div class="label">ICLR'24</div>
        </div>
        <div class="text-side">
            <ul>
                <strong> De novo Protein Design Using Geometric Vector Field Networks</strong> <br>
                Weian Mao*, <strong>Muzhi Zhu</strong>* , Zheng Sun*, Shuaike Shen, Lin Yuanbo Wu, Hao Chen, Chunhua Shen <br>
                The Twelfth International Conference on Learning Representations (ICLR'24) 2024. <br>
                (Spotlight) <br>
                <a href="https://github.com/aim-uofa/VFN">[code]</a> <a href="https://openreview.net/forum?id=9UIGyJJpay">[paper]</a> 
            </ul>
        </div>
    </div>            
</p>

<!-- @inproceedings{
    liu2024matcher,
    title={Matcher: Segment Anything with One Shot Using All-Purpose Feature Matching},
    author={Yang Liu and Muzhi Zhu and Hengtao Li and Hao Chen and Xinlong Wang and Chunhua Shen},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=yzRXdhk2he}
    } -->
<p>
    <div class="container">
        <div class="image-side">
            <img src="./paper_img/matcher.png" border="0" width="240">
            <div class="label">ICLR'24</div>
        </div>
        <div class="text-side">
            <ul>
                <strong> Matcher: Segment Anything with One Shot Using All-Purpose Feature Matching </strong> <br>
                Yang Liu*, <strong>Muzhi Zhu</strong>* , Hengtao Li*, Hao Chen, Xinlong Wang, Chunhua Shen <br>
                The Twelfth International Conference on Learning Representations (ICLR'24) 2024. <br>
                <a href="https://github.com/aim-uofa/Matcher">[code]</a> <a href="https://openreview.net/forum?id=yzRXdhk2he">[paper]</a> 
            </ul>
        </div>
    </div>            
</p>

<!-- <h1>A Simple Image Segmentation Framework via In-Context Examples </h1>

[Yang Liu](https://scholar.google.com/citations?user=9JcQ2hwAAAAJ&hl=en)<sup>1</sup>, &nbsp; 
[Chenchen Jing](https://jingchenchen.github.io/)<sup>1</sup>, &nbsp;
Hengtao Li<sup>1</sup>, &nbsp;
[Muzhi Zhu](https://scholar.google.com/citations?user=064gBH4AAAAJ&hl=en)<sup>1</sup>, &nbsp;
[Hao Chen](https://stan-haochen.github.io/)<sup>1</sup>, &nbsp;
[Xinlong Wang](https://www.xloong.wang/)<sup>2</sup>, &nbsp;
[Chunhua Shen](https://cshen.github.io/)<sup>1</sup>

<sup>1</sup>[Zhejiang University](https://www.zju.edu.cn/english/), &nbsp;
<sup>2</sup>[Beijing Academy of Artificial Intelligence](https://www.baai.ac.cn/english.html)

NeurIPS 2024 -->
<p>
    <div class="container">
        <div class="image-side">
            <img src="./paper_img/sine.png" border="0" width="240">
            <div class="label">NeurIPS'24</div>
        </div>
        <div class="text-side">
            <ul>
                <strong> A Simple Image Segmentation Framework via In-Context Examples </strong> <br>
                Yang Liu, Chenchen Jing, Hengtao Li, <strong>Muzhi Zhu</strong>, Hao Chen, Xinlong Wang, Chunhua Shen <br>
                Advances in Neural Information Processing Systems (NeurIPS'24), 2024. <br>
                <a href="https://github.com/aim-uofa/SINE">[code]</a> <a href="https://openreview.net/forum?id=3ACXaFxjTy">[paper]</a>
            </ul>
        </div>
    </div>  
</p>
<!-- https://link.springer.com/article/10.1007/s11263-024-02204-6
Yang Liu, Xinlong Wang, Muzhi Zhu, Yue Cao, Tiejun Huang & Chunhua Shen
International Journal of Computer Vision
Masked Channel Modeling for Bootstrapping Visual Pre-training -->
<p>
    <div class="container">
        <div class="image-side">
            <img src="./paper_img/mcm.png" border="0" width="240">
            <div class="label">IJCV'24</div>
        </div>
        <div class="text-side">
            <ul>
                <strong> Masked Channel Modeling for Bootstrapping Visual Pre-training </strong> <br>
                Yang Liu, Xinlong Wang, <strong>Muzhi Zhu</strong>, Yue Cao, Tiejun Huang, Chunhua Shen <br>
                International Journal of Computer Vision (IJCV'24), 2024. <br>
                <a href="https://github.com/aim-uofa">[code]</a> <a href="https://link.springer.com/article/10.1007/s11263-024-02204-6">[paper]</a>
            </ul>
        </div>
    </div>
</p>
<!-- <a href="pub.html">Full publication list</a> -->




<!--
<h2>Survey and View Points<small></small></h2>
<ul>
    
</ul>
-->
<!--
<h2>Conference Papers<small></small></h2>
<ul>
    <li>
        [C1] <strong>Muzhi Zhu</strong>, Kaifan Yang, Jiahong Zhang, Renjun Xu.  S2SNet: A Pretrained Neural Network for Superconductivity Discovery, The 31ST International Joint Conference on Artificial Intelligence (IJCAI), 2022. <a href="https://github.com/zjuKeLiu/S2SNet">[code]</a> <a href="https://www.ijcai.org/proceedings/2022/708">[paper]</a> <a  href="https://www.ijcai.org/proceedings/2022/bibtex/0708">[bib]</a>
    </li>
    <li>
        [C2] Qinghui Sun, Jie Gu, Xiaoxiao Xu, Renjun Xu, <strong>Muzhi Zhu</strong>, Bei Yang, Hong Liu, huan xu., Learning Interest-oriented Universal User Representation via Self-supervision, The 30th ACM International Conference on Multimedia (ACMMM), 2022.<a href="https://dl.acm.org/doi/10.1145/3503161.3548767">[paper]</a>
    </li>
    <li>
        [C3] <b>Muzhi Zhu</b>, Shangde Gao, Kaifan Yang, Yuqiang Han, PCVAE: a Physics-Informed Neural Network for Determining the Symmetry and Geometry of Crystals, 2023 International Joint Conference on Neural Networks (IJCNN) 2023. (oral) <a href="bibs/pcvae.bib">[bib]</a>
    </li>
    <li>
        [C4] Renjun Xu*, Kaifan Yang*, <strong>Muzhi Zhu</strong>*✉, Fengxiang He. Group Equivariant Vision Transformer. Conference on Uncertainty in Artificial Intelligence (UAI), 2023.<a href="bibs/GEViT.bib">[bib]</a>
    </li>
    <li>
        [C5] Bei Yang, Jie Gu, <strong>Muzhi Zhu</strong>, Xiaoxiao Xu, Renjun Xu, Hong Liu, Huan Xu, Empowering General-purpose User Representation with Full-life Cycle Behavior Modeling. Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2023.
    </li>
    <li>
        [C6] Shangde Gao*, Yichao Fu*, <strong>Muzhi Zhu</strong>*, Yuqiang Han. Contrastive Knowledge Amalgamation for Unsupervised Image Classification. International Conference on Artificial Neural Networks 2023.
    </li>
</ul>


<h2>Journal Papers<small></small></h2>
<ul>
    <li>
        [J1] Xin Tong, Renjun Xu, <strong>Muzhi Zhu</strong>, Liangliang Zhao, Weilai Zhu, Daomu Zhao. A Deep-Learning Approach for Low-Spatial-Coherence Imaging in Computer-Generated Holography, Advanced Photonics Research. <a href="https://onlinelibrary.wiley.com/doi/10.1002/adpr.202200264">[paper]</a> <a href="https://github.com/zjuKeLiu/U-RDN">[code]</a> <a  href="https://onlinelibrary.wiley.com/action/showCitFormats?doi=10.1002%2Fadpr.202200264">[bib]</a>
    </li>
    <li>
        [J2] <strong>Muzhi Zhu</strong>, Yuqiang Han, Zhichen Gong, Hongxia Xu. Low-Data Drug Design with Few-Shot Generative Domain Adaptation. BioEngineering.
    </li>
    <li>
        [J3] Shangde Gao*, Yichao Fu*, <strong>Muzhi Zhu*</strong>, Wei Gao, Hongxia Xu, Jian Wu, Yuqiang Han.  Collaborative knowledge amalgamation: Preserving discriminability and transferability in unsupervised learning. Information Sciences.
    </li>
</ul>

<br> ✉ Correspond author;  <b>*</b> Equal contribution.
-->
<!--
<h2>Selected Honors and Awards<small></small></h2>
-->


<h2>Academic Service <small></small></h2>
<li>
    Conference Reviewer: ICCV,ECCV, ICML,CVPR, NeurIPS, ICLR, AAAI.

    <!-- top Reviewer -->
    I am honored to be selected as a top reviewer for NeurIPS 2024.
</li>



<!-- <a href="https://clustrmaps.com/site/1bo3n"  title="Visit tracker for zjukeliu.github.io"><img src="//www.clustrmaps.com/map_v2.png?d=B5fwmGJ_EF2SXft9eqvqwSRv3hWvHeRegc-qAMWUY7c&cl=ffffff" /></a> -->

<!--
<h2>Honors Awarded</h2>
<table style="border-spacing:2px">
    <tbody>
        <tr><td>... TODO ...</td></tr>
    </tbody>
</table>
-->
<div id="footer">
    <div id="footer-text"></div>
</div>

</div>
Last updated on March 2025.
</body></html>
